{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6b79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, MaxPool2D,Flatten,Dropout \n",
    "from keras.callbacks import EarlyStopping \n",
    "from tqdm import tqdm\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f746c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08db3582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 80.95it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 84.72it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'D1/train'\n",
    "CATEGORIES = [\"qcerris\", \"qfrainetto\"]\n",
    "x_train = []\n",
    "y_train = []\n",
    "for category in CATEGORIES:  \n",
    "    path = os.path.join(DATADIR,category) \n",
    "    class_num = CATEGORIES.index(category) \n",
    "    for img in tqdm(os.listdir(path)): \n",
    "        img_array = cv2.imread(os.path.join(path,img)) \n",
    "        new_array = cv2.resize(img_array, (IMAGE_WIDTH, IMAGE_HEIGHT)) \n",
    "        x_train.append(new_array)\n",
    "        y_train.append(class_num)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b34ffc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 95.21it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 76.48it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'D1/test'\n",
    "x_test = []\n",
    "y_test = []\n",
    "for category in CATEGORIES:  \n",
    "    path = os.path.join(DATADIR,category) \n",
    "    class_num = CATEGORIES.index(category) \n",
    "    for img in tqdm(os.listdir(path)): \n",
    "        img_array = cv2.imread(os.path.join(path,img)) \n",
    "        new_array = cv2.resize(img_array, (IMAGE_WIDTH, IMAGE_HEIGHT)) \n",
    "        x_test.append(new_array)\n",
    "        y_test.append(class_num)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2a7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 40,\n",
    "        shear_range = 0.3,\n",
    "        zoom_range = 0.3,\n",
    "        horizontal_flip = True,\n",
    "        brightness_range = (0.5, 1.5))\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "    \n",
    "for i in range(len(x_train)):\n",
    "        img = x_train[i].reshape((1,) + x_train[i].shape)\n",
    "        for batch in datagen.flow(img, batch_size=1):\n",
    "            augmented_images.append(batch[0])\n",
    "            augmented_labels.append(y_train[i])\n",
    "            if len(augmented_images) >= 2:  # Adjust the number of augmentations per image\n",
    "                break\n",
    "\n",
    "x_train = np.concatenate([x_train, np.array(augmented_images)])\n",
    "y_train = np.concatenate([y_train, np.array(augmented_labels)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565cc980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (209, 224, 224, 3)\n",
      "y_train shape: (209,)\n",
      "x_test shape: (49, 224, 224, 3)\n",
      "y_test shape: (49,)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "    \n",
    "for i in range(len(x_test)):\n",
    "        img = x_test[i].reshape((1,) + x_test[i].shape)\n",
    "        for batch in datagen.flow(img, batch_size=1):\n",
    "            augmented_images.append(batch[0])\n",
    "            augmented_labels.append(y_test[i])\n",
    "            if len(augmented_images) >= 2:  # Adjust the number of augmentations per image\n",
    "                break\n",
    "\n",
    "x_test = np.concatenate([x_test, np.array(augmented_images)])\n",
    "y_test = np.concatenate([y_test, np.array(augmented_labels)])\n",
    "\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af837644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "# Shuffle the dataset\n",
    "num_samples = len(x_train)\n",
    "indices = np.random.permutation(num_samples)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "# Shuffle the dataset\n",
    "num_samples = len(x_test)\n",
    "indices = np.random.permutation(num_samples)\n",
    "x_test = x_test[indices]\n",
    "y_test = y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816d7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3392d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.astype(int)].T\n",
    "    return Y.T\n",
    "\n",
    "# One-hot encode the target labels\n",
    "y_train = convert_to_one_hot(y_train, 2)\n",
    "\n",
    "# One-hot encode the target labels\n",
    "y_test = convert_to_one_hot(y_test, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0bb40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "\n",
    "x_test = x_test / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3849132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21137986 (80.64 MB)\n",
      "Trainable params: 6423298 (24.50 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = Sequential()\n",
    "VGG16_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "for layer in VGG16_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False  # Not trainable weights\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0254909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 44s 9s/step - loss: 1.7523 - accuracy: 0.8836 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 42s 9s/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 45s 10s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 47s 10s/step - loss: 1.7576e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 45s 10s/step - loss: 1.6824e-05 - accuracy: 1.0000 - val_loss: 5.0248e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 43s 9s/step - loss: 6.5156e-06 - accuracy: 1.0000 - val_loss: 2.7766e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 42s 9s/step - loss: 2.5627e-06 - accuracy: 1.0000 - val_loss: 1.9052e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 47s 10s/step - loss: 1.7043e-06 - accuracy: 1.0000 - val_loss: 1.5013e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 47s 10s/step - loss: 1.2799e-06 - accuracy: 1.0000 - val_loss: 1.2926e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 49s 10s/step - loss: 1.0697e-06 - accuracy: 1.0000 - val_loss: 1.1768e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a85dd41990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping_monitor = EarlyStopping(patience=3, verbose = 1)\n",
    "model.fit(x_train, y_train, epochs=10, validation_split = 0.3, callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "340ef6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step\n",
      "[[25  0]\n",
      " [ 0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        49\n",
      "   macro avg       1.00      1.00      1.00        49\n",
      "weighted avg       1.00      1.00      1.00        49\n",
      "\n",
      "Accuracy:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F_ measure:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Define your class labels\n",
    "class_labels = ['q_aff_cerris', 'q_rubur_f_purpubascens']\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy = (conf_mat[0, 0] + conf_mat[1, 1]) / np.sum(conf_mat)\n",
    "precision = conf_mat[1, 1] / (conf_mat[1, 1] + conf_mat[0, 1])\n",
    "recall = conf_mat[1, 1] / (conf_mat[1, 1] + conf_mat[1, 0])\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(conf_mat)\n",
    "print(class_report)\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F_ measure: ', f1_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
